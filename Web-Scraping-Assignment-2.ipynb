{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed737cec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2028/1699635188.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mselenium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mby\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7873d4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed h11-0.13.0 outcome-1.2.0 selenium-4.3.0 trio-0.21.0 trio-websocket-0.9.2 wsproto-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4106742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d0a7d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location.\n",
    "\n",
    "#You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b22c526",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb8bd034",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search job bar using id\n",
    "search_job=driver.find_element(By.CLASS_NAME,'suggestor-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea762a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8001489d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"b3f745d1ff15f81468be729ddde3404d\", element=\"993f6fa3-c08d-4ccc-add9-1d1933c1fa22\")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#finding web element for search icon bar using relative xpath\n",
    "search_locn=driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_locn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87862be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for job locn on bar\n",
    "search_locn.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08bb49af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "search_btn=driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d21ed2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the job title\n",
    "job_title=[]\n",
    "\n",
    "job_tag=driver.find_elements(By.XPATH, \"//a[@class='title fw500 ellipsis']\")\n",
    "job_tag=job_tag[0:10]\n",
    "for i in job_tag:\n",
    "    job_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3980a63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting job location\n",
    "job_location=[]\n",
    "\n",
    "job_loc=driver.find_elements(By.XPATH, \"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "job_loc=job_loc[0:10]\n",
    "for i in job_loc:\n",
    "    job_location.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b27d2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting company name\n",
    "company=[]\n",
    "\n",
    "comp=driver.find_elements(By.XPATH, \"//div[@class='mt-7 companyInfo subheading lh16']\")\n",
    "comp=comp[0:10]\n",
    "for i in comp:\n",
    "    company.append(i.text.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "538e5ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Experience\n",
    "exp=[]\n",
    "\n",
    "expn=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "expn=expn[0:10]\n",
    "for i in expn:\n",
    "    exp.append(i.text)\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b0baefe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Job-Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr.Business Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, karnataka\\n(WFH during Co...</td>\n",
       "      <td>Collabera</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Job opportunity For Data Analyst at Trellance ...</td>\n",
       "      <td>Bangalore/Bengaluru, Ahmedabad</td>\n",
       "      <td>CURise Analytics Pvt. Ltd.</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru(Old Madras Road)</td>\n",
       "      <td>KrazyBee</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring For Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Associate Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Optum</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst/Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Meesho</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-Title  \\\n",
       "0                           Sr.Business Data Analyst   \n",
       "1  Job opportunity For Data Analyst at Trellance ...   \n",
       "2                                Senior Data Analyst   \n",
       "3            Master Data Management Business Analyst   \n",
       "4                                    Sr Data Analyst   \n",
       "5                            Hiring For Data Analyst   \n",
       "6                                       Data Analyst   \n",
       "7                             Associate Data Analyst   \n",
       "8                             Associate Data Analyst   \n",
       "9                   Data Analyst/Senior Data Analyst   \n",
       "\n",
       "                                        Job-Location  \\\n",
       "0  Bangalore/Bengaluru, karnataka\\n(WFH during Co...   \n",
       "1                     Bangalore/Bengaluru, Ahmedabad   \n",
       "2               Bangalore/Bengaluru(Old Madras Road)   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8                                Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                 Company_Name Experience_Required  \n",
       "0                   Collabera            6-11 Yrs  \n",
       "1  CURise Analytics Pvt. Ltd.             0-2 Yrs  \n",
       "2                    KrazyBee             3-6 Yrs  \n",
       "3                   Accenture             6-8 Yrs  \n",
       "4             Thomson Reuters             5-8 Yrs  \n",
       "5                    Flipkart             2-5 Yrs  \n",
       "6                       Wipro             4-9 Yrs  \n",
       "7                       Optum             2-7 Yrs  \n",
       "8                       Optum             1-4 Yrs  \n",
       "9                      Meesho             3-6 Yrs  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creaing the data frame to get top 10 results\n",
    "\n",
    "data=pd.DataFrame({'Job-Title':job_title, 'Job-Location':job_location,'Company_Name':company,'Experience_Required':exp})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "410a9d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location.\n",
    "\n",
    "#You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abac69ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f095fc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search job bar using id\n",
    "search_job=driver.find_element(By.CLASS_NAME,'suggestor-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9cbf50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "00ce2fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search icon bar using relative xpath\n",
    "search_locn=driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[3]/div/div/div[5]/div/div/div/input')\n",
    "search_locn.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28b644e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking using absolute xpath function\n",
    "search_btn=driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[3]/div/div/div[6]')\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffa7cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company=[]\n",
    "\n",
    "job_tag=driver.find_elements(By.XPATH, \"//a[@class='title fw500 ellipsis']\")\n",
    "job_tag=job_tag[0:10]\n",
    "for i in job_tag:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "job_loc=driver.find_elements(By.XPATH, \"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "job_loc=job_loc[0:10]\n",
    "for i in job_loc:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "comp=driver.find_elements(By.XPATH, \"//div[@class='mt-7 companyInfo subheading lh16']\")\n",
    "comp=comp[0:10]\n",
    "for i in comp:\n",
    "    company.append(i.text.split('\\n')[0])\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd4d0128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Job-Location</th>\n",
       "      <th>Company_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urgent Job Opening For AI Practitioner - Data ...</td>\n",
       "      <td>Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiring For Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune</td>\n",
       "      <td>TATA CONSULTANCY SERVICES (TCS)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Applied Materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data &amp; Analytics Tech - Informatica Cloud- Sen...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PwC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataiku Consultant</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Research and Development -AI/ML -(PhD )</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Hyderabad/Secunder...</td>\n",
       "      <td>EXL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Opportunity For Data Scientist - Female Candid...</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...</td>\n",
       "      <td>PayU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Science Engineer</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Science - Engineering Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Mumbai</td>\n",
       "      <td>Paytm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EY GBS - Assistant Director - Data Science (10...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>EYGBS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-Title  \\\n",
       "0  Urgent Job Opening For AI Practitioner - Data ...   \n",
       "1                   Hiring For Senior Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3  Data & Analytics Tech - Informatica Cloud- Sen...   \n",
       "4                                 Dataiku Consultant   \n",
       "5            Research and Development -AI/ML -(PhD )   \n",
       "6  Opportunity For Data Scientist - Female Candid...   \n",
       "7                       Senior Data Science Engineer   \n",
       "8                 Data Science - Engineering Manager   \n",
       "9  EY GBS - Assistant Director - Data Science (10...   \n",
       "\n",
       "                                        Job-Location  \\\n",
       "0  Bangalore/Bengaluru, Kochi/Cochin, New Delhi, ...   \n",
       "1                          Bangalore/Bengaluru, Pune   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                 Bangalore/Bengaluru, Pune, Chennai   \n",
       "5  Bangalore/Bengaluru, Noida, Hyderabad/Secunder...   \n",
       "6  Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...   \n",
       "7  Bangalore/Bengaluru, Gurgaon/Gurugram, Mumbai ...   \n",
       "8                 Bangalore/Bengaluru, Noida, Mumbai   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                      Company_Name  \n",
       "0                            Wipro  \n",
       "1  TATA CONSULTANCY SERVICES (TCS)  \n",
       "2                Applied Materials  \n",
       "3                              PwC  \n",
       "4                            Wipro  \n",
       "5                              EXL  \n",
       "6                             PayU  \n",
       "7                Fractal Analytics  \n",
       "8                            Paytm  \n",
       "9                            EYGBS  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating data frame to get to 10 jobs data\n",
    "data=pd.DataFrame({'Job-Title':job_title, 'Job-Location':job_location,'Company_Name':company})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6646ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3: In this question you have to scrape data using the filters available on the webpage\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "06f584b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08045bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search job bar using id\n",
    "search_job=driver.find_element(By.CLASS_NAME,'suggestor-input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5d620c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write on search bar\n",
    "search_job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29bdc787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding web element for search icon bar using relative xpath\n",
    "search_btn=driver.find_element(By.XPATH, '/html/body/div/div[2]/div[3]/div/div/div[6]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f30546ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74db3ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter=driver.find_element(By.XPATH, '/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[5]/div[2]/div[3]/label/p/span[1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d76dcf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a38b6376",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_filter=driver.find_element(By.XPATH,'/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[6]/div[2]/div[2]/label/p/span[1]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2749c642",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3f26920",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company=[]\n",
    "exp=[]\n",
    "\n",
    "job_tag=driver.find_elements(By.XPATH, \"//a[@class='title fw500 ellipsis']\")\n",
    "job_tag=job_tag[0:10]\n",
    "for i in job_tag:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "job_loc=driver.find_elements(By.XPATH, \"//li[@class='fleft grey-text br2 placeHolderLi location']\")\n",
    "job_loc=job_loc[0:10]\n",
    "for i in job_loc:\n",
    "    job_location.append(i.text)\n",
    "    \n",
    "comp=driver.find_elements(By.XPATH, \"//div[@class='mt-7 companyInfo subheading lh16']\")\n",
    "comp=comp[0:10]\n",
    "for i in comp:\n",
    "    company.append(i.text.split('\\n')[0])\n",
    "    \n",
    "expn=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "expn=expn[0:10]\n",
    "for i in expn:\n",
    "    exp.append(i.text)\n",
    "\n",
    "    \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "551d2a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-Title</th>\n",
       "      <th>Job-Location</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Experience_Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Noida/Bangalore</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Associate - Data Science</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...</td>\n",
       "      <td>Black Turtle</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>8KMiles Software Services</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist For Healthcare Product team</td>\n",
       "      <td>Delhi / NCR, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>8KMiles Software Services</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist - Machine learning AI</td>\n",
       "      <td>Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...</td>\n",
       "      <td>Teq Analytics</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist - MIND Infotech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>MOTHERSONSUMI INFOTECH &amp; DESIGNS LIMITED</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Knowledge/Data Scientist</td>\n",
       "      <td>Delhi / NCR</td>\n",
       "      <td>BOLD Technology Systems</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Job-Title  \\\n",
       "0             DigitalBCG GAMMA Data Scientist   \n",
       "1            Data Scientist - Noida/Bangalore   \n",
       "2             Senior Associate - Data Science   \n",
       "3  Data Scientist For Healthcare Product team   \n",
       "4  Data Scientist For Healthcare Product team   \n",
       "5        Data Scientist - Machine learning AI   \n",
       "6              Data Scientist - MIND Infotech   \n",
       "7           Data Scientist - Engine Algorithm   \n",
       "8                    Knowledge/Data Scientist   \n",
       "9                              Data Scientist   \n",
       "\n",
       "                                        Job-Location  \\\n",
       "0                     New Delhi, Bangalore/Bengaluru   \n",
       "1                         Noida, Bangalore/Bengaluru   \n",
       "2  Mumbai, Hyderabad/Secunderabad, Gurgaon/Gurugr...   \n",
       "3          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "4          Delhi / NCR, Chennai, Bangalore/Bengaluru   \n",
       "5  Delhi / NCR, Bangalore/Bengaluru, Mumbai (All ...   \n",
       "6                                              Noida   \n",
       "7  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...   \n",
       "8                                        Delhi / NCR   \n",
       "9             Delhi / NCR, Pune, Bangalore/Bengaluru   \n",
       "\n",
       "                               Company_Name Experience_Required  \n",
       "0                   Boston Consulting Group             2-5 Yrs  \n",
       "1                                       EXL            5-10 Yrs  \n",
       "2                              Black Turtle             4-7 Yrs  \n",
       "3                 8KMiles Software Services             2-7 Yrs  \n",
       "4                 8KMiles Software Services             2-7 Yrs  \n",
       "5                             Teq Analytics             3-8 Yrs  \n",
       "6  MOTHERSONSUMI INFOTECH & DESIGNS LIMITED             4-8 Yrs  \n",
       "7                              Primo Hiring             1-3 Yrs  \n",
       "8                   BOLD Technology Systems             3-6 Yrs  \n",
       "9   Mount Talent Consulting Private Limited             2-4 Yrs  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating data frame to get the result\n",
    "data=pd.DataFrame({'Job-Title':job_title, 'Job-Location':job_location,'Company_Name':company,'Experience_Required':exp})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8afdbc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "\n",
    "#Brand\n",
    "#Product Description\n",
    "#Price\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c18d9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2906660",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5b4534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7af78bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag=driver.find_element(By.CLASS_NAME, \"_3704LK\")\n",
    "search_tag.send_keys(\"Sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e215ba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.CLASS_NAME, \"L0Z3Pu\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8de7627c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating required list for processing\n",
    "brand=[]\n",
    "product_dis=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#Defining a function that include scrapping functions\n",
    "def scrap():\n",
    "    \n",
    "    brnd=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brnd:\n",
    "        if(len(brand)==100):\n",
    "            break\n",
    "        else:\n",
    "            brand.append(i.text)\n",
    "        dis=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "        for i in dis:\n",
    "            if(len(product_dis)==100):\n",
    "                break\n",
    "            else:\n",
    "                product_dis.append(i.text)\n",
    "        pri=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "        for j in pri:\n",
    "            if(len(price)==100):\n",
    "                break\n",
    "            else:\n",
    "                price.append(j.text)\n",
    "        dis=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "        for j in dis:\n",
    "            if(len(discount)==100):\n",
    "                break\n",
    "            else:\n",
    "                discount.append(j.text)\n",
    "\n",
    "#now we are going to 100 sunglasses \n",
    "for i in range(0,3):\n",
    "    if(i==0):\n",
    "        scrap()\n",
    "    elif i==1:\n",
    "        driver.find_element(By.CLASS_NAME,\"_1LKTO3\").click()\n",
    "        time.sleep(3)\n",
    "        scrap()\n",
    "    elif(i==2):\n",
    "        driver.find_element(By.XPATH,'/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]').click()\n",
    "        time.sleep(3)\n",
    "        scrap()\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a025cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Details</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (53)</td>\n",
       "      <td>₹313</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection, Gradient Round Sunglasses (Free...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DAHAAZIL</td>\n",
       "      <td>UV Protection, Night Vision, Riding Glasses Wa...</td>\n",
       "      <td>₹177</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹264</td>\n",
       "      <td>89% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹319</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹359</td>\n",
       "      <td>86% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹331</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹639</td>\n",
       "      <td>20% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROYAL SON</td>\n",
       "      <td>Polarized, Riding Glasses, Night Vision Sports...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                    Product Details Price  \\\n",
       "0     Silver Kartz           UV Protection Clubmaster Sunglasses (53)  ₹313   \n",
       "1   ROZZETTA CRAFT  UV Protection, Gradient Round Sunglasses (Free...  ₹379   \n",
       "2         DAHAAZIL  UV Protection, Night Vision, Riding Glasses Wa...  ₹177   \n",
       "3         Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹639   \n",
       "4        New Specs   UV Protection Rectangular Sunglasses (Free Size)  ₹264   \n",
       "..             ...                                                ...   ...   \n",
       "95       ROYAL SON  UV Protection Retro Square Sunglasses (Free Size)  ₹319   \n",
       "96       New Specs              UV Protection Aviator Sunglasses (58)  ₹359   \n",
       "97          PIRASO  UV Protection, Gradient Retro Square Sunglasse...  ₹331   \n",
       "98    Singco India       UV Protection Aviator Sunglasses (Free Size)  ₹639   \n",
       "99       ROYAL SON  Polarized, Riding Glasses, Night Vision Sports...  ₹499   \n",
       "\n",
       "   Discount  \n",
       "0   79% off  \n",
       "1   81% off  \n",
       "2   82% off  \n",
       "3   20% off  \n",
       "4   89% off  \n",
       "..      ...  \n",
       "95  68% off  \n",
       "96  86% off  \n",
       "97  83% off  \n",
       "98  20% off  \n",
       "99  78% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sunglass=pd.DataFrame({'Brand':brand,'Product Details':product_dis,'Price':price,'Discount':discount})\n",
    "Sunglass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5e7359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "#This task will be done in following steps:\n",
    "\n",
    "#First get the webpage https://www.flipkart.com/\n",
    "#Enter “iphone 11” in “Search” field .\n",
    "#Then click the search button.\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0b23fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bf86270",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d3cee1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8cfce41",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_tag.send_keys(\"iphone 11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b698e4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8dc51c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now get the newly opened window\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80acb71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating=[]\n",
    "review_sum=[]\n",
    "review_dis=[]\n",
    "\n",
    "j=1\n",
    "def i_scrap():\n",
    "    rate=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rate:\n",
    "        rating.append(i.text)\n",
    "    review=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review:\n",
    "        review_sum.append(i.text)\n",
    "    rdis=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')\n",
    "    for i in rdis:\n",
    "        review_dis.append(i.text)\n",
    "i_scrap()\n",
    "next_b=driver.find_elements(By.CLASS_NAME,\"ge-49M\")\n",
    "for b in next_b:\n",
    "    i_scrap()\n",
    "len(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d03bf8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_Summery</th>\n",
       "      <th>Review_Disciption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_Summery  \\\n",
       "0       5       Simply awesome   \n",
       "1       5     Perfect product!   \n",
       "2       5  Best in the market!   \n",
       "3       5   Highly recommended   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5            Fabulous!   \n",
       "96      5        Great product   \n",
       "97      5    Worth every penny   \n",
       "98      4          Good choice   \n",
       "99      5   Highly recommended   \n",
       "\n",
       "                                    Review_Disciption  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   What a camera .....just awesome ..you can feel...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  This is my first iOS phone. I am very happy wi...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  i11 is worthy to buy, too much happy with the ...  \n",
       "98  So far it’s been an AMAZING experience coming ...  \n",
       "99  iphone 11 is a very good phone to buy only if ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone_rating=pd.DataFrame({'Rating':rating,'Review_Summery':review_sum,'Review_Disciption':review_dis})\n",
    "iphone_rating[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d0fa48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55e1df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45bb55f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a46a5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf25499",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_tag=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "search_tag.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c862130",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b55b22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button=driver.find_element(By.CLASS_NAME, \"L0Z3Pu\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14143358",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "product_dis=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#Defining a function that include scrapping functions\n",
    "def scrap():\n",
    "    \n",
    "    brnd=driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brnd:\n",
    "        if(len(brand)==100):\n",
    "            break\n",
    "        else:\n",
    "            brand.append(i.text)\n",
    "        dis=driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "        for i in dis:\n",
    "            if(len(product_dis)==100):\n",
    "                break\n",
    "            else:\n",
    "                product_dis.append(i.text)\n",
    "        pri=driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]')\n",
    "        for j in pri:\n",
    "            if(len(price)==100):\n",
    "                break\n",
    "            else:\n",
    "                price.append(j.text)\n",
    "        dis=driver.find_elements(By.XPATH, '//div[@class=\"_3Ay6Sb\"]')\n",
    "        for j in dis:\n",
    "            if(len(discount)==100):\n",
    "                break\n",
    "            else:\n",
    "                discount.append(j.text)\n",
    "\n",
    "#now we are going to 100 sunglasses \n",
    "for i in range(0,3):\n",
    "    if(i==0):\n",
    "        scrap()\n",
    "    elif i==1:\n",
    "        driver.find_element(By.CLASS_NAME,\"_1LKTO3\").click()\n",
    "        time.sleep(3)\n",
    "        scrap()\n",
    "    elif(i==2):\n",
    "        driver.find_element(By.XPATH, '/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]').click()\n",
    "        time.sleep(3)\n",
    "        scrap()\n",
    "        \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b1d782b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Details</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ROCKFIELD</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹539</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZF - ALFIYA</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WOODLAND</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,797</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹284</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Puma Smash v2 L Sneakers For Men</td>\n",
       "      <td>₹1,658</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>KEYTAR</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>KNIGHT WALKERS</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹449</td>\n",
       "      <td>55% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>corsac</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹539</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Roadster</td>\n",
       "      <td>Puma Smash v2 L Sneakers For Men</td>\n",
       "      <td>₹539</td>\n",
       "      <td>46% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>KEYTAR</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹664</td>\n",
       "      <td>66% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                    Product Details   Price  \\\n",
       "0        ROCKFIELD                                   Sneakers For Men    ₹539   \n",
       "1      ZF - ALFIYA                                   Sneakers For Men    ₹449   \n",
       "2         WOODLAND                                   Sneakers For Men  ₹1,797   \n",
       "3           BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men    ₹284   \n",
       "4             PUMA                   Puma Smash v2 L Sneakers For Men  ₹1,658   \n",
       "..             ...                                                ...     ...   \n",
       "95          KEYTAR  Lightweight Pack Of 1 Trendy Sneakers Sneakers...    ₹449   \n",
       "96  KNIGHT WALKERS                                   Sneakers For Men    ₹449   \n",
       "97          corsac  Luxury Fashionable casual sneaker shoes Sneake...    ₹539   \n",
       "98        Roadster                   Puma Smash v2 L Sneakers For Men    ₹539   \n",
       "99          KEYTAR                                   Sneakers For Men    ₹664   \n",
       "\n",
       "   Discount  \n",
       "0   64% off  \n",
       "1   55% off  \n",
       "2   40% off  \n",
       "3   78% off  \n",
       "4   52% off  \n",
       "..      ...  \n",
       "95  77% off  \n",
       "96  55% off  \n",
       "97  46% off  \n",
       "98  46% off  \n",
       "99  66% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating one data fram using scrapped data             \n",
    "sneakers=pd.DataFrame({'Brand':brand,'Product Details':product_dis,'Price':price,'Discount':discount})\n",
    "sneakers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26aa13b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7: Go to webpage https://www.amazon.in/\n",
    "\n",
    "#Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "\n",
    "#After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "\n",
    "#Title\n",
    "#Ratings\n",
    "#Price\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "840d3253",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eca0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f2515a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_searchtext=driver.find_element(By.XPATH, '/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "amazon_searchtext.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "431a333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a10aa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, '/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c947bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, '/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[2]/li[12]/span/a/span').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25d74ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lap_title=[]\n",
    "lap_pri=[]\n",
    "lap_rate=[]\n",
    "#def lap_scrap():\n",
    "ti=driver.find_elements(By.XPATH,'//a[@class=\"a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal\"]')\n",
    "for i in ti:\n",
    "    if(len(lap_title)==10):\n",
    "        break\n",
    "    else:\n",
    "        lap_title.append(i.text)\n",
    "rt=driver.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]/span[1]')\n",
    "for i in rt:\n",
    "    if(len(lap_rate)==10):\n",
    "        break\n",
    "    else:\n",
    "        lap_rate.append(i.get_attribute('aria-label'))\n",
    "\n",
    "pr=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in pr:\n",
    "    if(len(lap_pri)==10):\n",
    "        break\n",
    "    else:\n",
    "        lap_pri.append(i.text)\n",
    "        \n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6bb952ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lap Titile</th>\n",
       "      <th>Lap Price</th>\n",
       "      <th>Lap Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP 15s 12thGen IntelCore i5 8GB RAM/512GB SSD ...</td>\n",
       "      <td>54,290</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Acer Aspire 5 A515-56 Thin and Light Laptop | ...</td>\n",
       "      <td>47,990</td>\n",
       "      <td>3.7 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mi Notebook Pro Qhd+ IPS Anti Glare Display In...</td>\n",
       "      <td>57,990</td>\n",
       "      <td>4.3 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad 3 11th Gen Intel Core i3 15.6\" ...</td>\n",
       "      <td>36,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i5 15....</td>\n",
       "      <td>59,990</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 10th Gen Intel Core i5 1...</td>\n",
       "      <td>45,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hp 15S 11Th Gen Intel Core I5 15.6 Inches Fhd ...</td>\n",
       "      <td>52,490</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mi Notebook Ultra 3.2K Resolution Display Inte...</td>\n",
       "      <td>61,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSI Modern 14, Intel i5-10210U, 14\" FHD IPS-Le...</td>\n",
       "      <td>41,990</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lenovo ThinkBook 14 Intel Core i5 11th Gen 14\"...</td>\n",
       "      <td>55,990</td>\n",
       "      <td>3.4 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Lap Titile Lap Price  \\\n",
       "0  HP 15s 12thGen IntelCore i5 8GB RAM/512GB SSD ...    54,290   \n",
       "1  Acer Aspire 5 A515-56 Thin and Light Laptop | ...    47,990   \n",
       "2  Mi Notebook Pro Qhd+ IPS Anti Glare Display In...    57,990   \n",
       "3  Lenovo IdeaPad 3 11th Gen Intel Core i3 15.6\" ...    36,990   \n",
       "4  Lenovo ThinkBook 15 Intel 11th Gen Core i5 15....    59,990   \n",
       "5  Lenovo IdeaPad Slim 3 10th Gen Intel Core i5 1...    45,990   \n",
       "6  Hp 15S 11Th Gen Intel Core I5 15.6 Inches Fhd ...    52,490   \n",
       "7  Mi Notebook Ultra 3.2K Resolution Display Inte...    61,990   \n",
       "8  MSI Modern 14, Intel i5-10210U, 14\" FHD IPS-Le...    41,990   \n",
       "9  Lenovo ThinkBook 14 Intel Core i5 11th Gen 14\"...    55,990   \n",
       "\n",
       "           Lap Rating  \n",
       "0  4.2 out of 5 stars  \n",
       "1  3.7 out of 5 stars  \n",
       "2  4.3 out of 5 stars  \n",
       "3  4.2 out of 5 stars  \n",
       "4  4.0 out of 5 stars  \n",
       "5  4.2 out of 5 stars  \n",
       "6  4.1 out of 5 stars  \n",
       "7  4.2 out of 5 stars  \n",
       "8  4.2 out of 5 stars  \n",
       "9  3.4 out of 5 stars  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lap=pd.DataFrame({'Lap Titile':lap_title,'Lap Price':lap_pri,'Lap Rating':lap_rate})\n",
    "lap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9449b8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location.\n",
    "\n",
    "#You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8354f697",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88f2de56",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,\"/html/body/div[1]/nav/nav/a[6]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22365355",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, '/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input').send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87f2c98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.CLASS_NAME,\"ctas-btn-medium\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60be9cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH, \"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb1c935b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input').send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a583a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df608c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "192f6bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "company=[]\n",
    "no_day=[]\n",
    "com_rating=[]\n",
    "com=driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for i in com:\n",
    "    company.append(i.text.split('\\n')[0])\n",
    "    if len(com_rating)==0:\n",
    "        com_rating.append(i.text.split('\\n')[2])\n",
    "    else:\n",
    "        com_rating.append(i.text.split('\\n')[1])\n",
    "com_rating=com_rating[:10]\n",
    "company=company[:10]\n",
    "days=driver.find_elements(By.XPATH,'//span[@class=\"body-small-l\"]')\n",
    "for i in days:\n",
    "    no_day.append(i.text.split(','))\n",
    "no_day=no_day[0::2]\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d49263e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Company Rating</th>\n",
       "      <th>No of Days ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>4.1</td>\n",
       "      <td>[9d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>4.1</td>\n",
       "      <td>[16d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>4.0</td>\n",
       "      <td>[7d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dew Solutions Pvt. Ltd.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>[14d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>InfoEdge India Ltd.</td>\n",
       "      <td>3.9</td>\n",
       "      <td>[15d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Info Edge India Limited</td>\n",
       "      <td>3.9</td>\n",
       "      <td>[15d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Info Edge India Limited</td>\n",
       "      <td>3.9</td>\n",
       "      <td>[15d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Latent bridge</td>\n",
       "      <td>4.5</td>\n",
       "      <td>[2d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Careerera</td>\n",
       "      <td>3.8</td>\n",
       "      <td>[29d ago]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Careernet Consulting</td>\n",
       "      <td>3.9</td>\n",
       "      <td>[15d ago]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Company Company Rating  \\\n",
       "0  Optum Global Solutions (India) Private Limited            4.1   \n",
       "1  Optum Global Solutions (India) Private Limited            4.1   \n",
       "2                   GENPACT India Private Limited            4.0   \n",
       "3                         Dew Solutions Pvt. Ltd.            4.3   \n",
       "4                             InfoEdge India Ltd.            3.9   \n",
       "5                         Info Edge India Limited            3.9   \n",
       "6                         Info Edge India Limited            3.9   \n",
       "7                                   Latent bridge            4.5   \n",
       "8                                       Careerera            3.8   \n",
       "9                            Careernet Consulting            3.9   \n",
       "\n",
       "  No of Days ago  \n",
       "0       [9d ago]  \n",
       "1      [16d ago]  \n",
       "2       [7d ago]  \n",
       "3      [14d ago]  \n",
       "4      [15d ago]  \n",
       "5      [15d ago]  \n",
       "6      [15d ago]  \n",
       "7       [2d ago]  \n",
       "8      [29d ago]  \n",
       "9      [15d ago]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs=pd.DataFrame({'Company':company,'Company Rating':com_rating,'No of Days ago':no_day})\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7dd2078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "\n",
    "#You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "\n",
    "#connect to the web driver\n",
    "\n",
    "driver=webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dabb8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef80e004",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,\"/html/body/div[1]/nav/nav/a[4]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38761a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input').send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bff6426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google',\n",
       " 'Microsoft Corporation',\n",
       " 'Goldman Sachs',\n",
       " 'Tekion',\n",
       " 'Amazon',\n",
       " 'Servicenow Software Development India',\n",
       " 'Flipkart',\n",
       " 'Walmart',\n",
       " 'PayPal',\n",
       " 'Myntra']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now  we want to extract all  the  10 comapny names here \n",
    "company_names=[]\n",
    "co_nametag= driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]/a')\n",
    "\n",
    "for i in  co_nametag:\n",
    "    com_name=(i.text.split('\\n')[0])\n",
    "    company_names.append(com_name)\n",
    "company_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "039f314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will fetch the min, avg and max Salary\n",
    "avg_sal=[]\n",
    "min_sal=[]\n",
    "max_sal=[]\n",
    "asal=driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for i in asal:\n",
    "    avg_sal.append(i.text)\n",
    "misal=driver.find_elements(By.XPATH,'//div[@class=\"value body-medium\"]')\n",
    "for i in misal:\n",
    "    min_sal.append(i.text)\n",
    "max_sal=min_sal[1::2]\n",
    "min_sal=min_sal[0::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c039d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1-3 yrs experience (based on 35 salaries)',\n",
       " '1-4 yrs experience (based on 274 salaries)',\n",
       " '2 yrs experience (based on 18 salaries)',\n",
       " '2-4 yrs experience (based on 35 salaries)',\n",
       " '1-4 yrs experience (based on 122 salaries)',\n",
       " '2-4 yrs experience (based on 60 salaries)',\n",
       " '1-4 yrs experience (based on 64 salaries)',\n",
       " '1-4 yrs experience (based on 87 salaries)',\n",
       " '1-2 yrs experience (based on 29 salaries)',\n",
       " '1 yr experience (based on 10 salaries)']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now  we  will  be fetching  the  experience   here \n",
    "company_exp=[]\n",
    "exp_tag= driver.find_elements(By.XPATH, '//div[@class=\"sbold-list-header\"]')\n",
    "for i in exp_tag:\n",
    "    com_exp=i.text\n",
    "    company_exp.append(com_exp)\n",
    "company_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ad1e2b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comapnay_names</th>\n",
       "      <th>minimum_salary</th>\n",
       "      <th>Average_salary</th>\n",
       "      <th>Maximum_salary</th>\n",
       "      <th>Experiences_req</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 31.3L</td>\n",
       "      <td>₹ 65.0L</td>\n",
       "      <td>1-3 yrs experience (based on 35 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>₹ 13.0L</td>\n",
       "      <td>₹ 24.0L</td>\n",
       "      <td>₹ 50.0L</td>\n",
       "      <td>1-4 yrs experience (based on 274 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>₹ 34.0L</td>\n",
       "      <td>2 yrs experience (based on 18 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tekion</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 21.2L</td>\n",
       "      <td>₹ 33.0L</td>\n",
       "      <td>2-4 yrs experience (based on 35 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>₹ 8.0L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>1-4 yrs experience (based on 122 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Servicenow Software Development India</td>\n",
       "      <td>₹ 13.0L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 28.0L</td>\n",
       "      <td>2-4 yrs experience (based on 60 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Flipkart</td>\n",
       "      <td>₹ 7.5L</td>\n",
       "      <td>₹ 20.4L</td>\n",
       "      <td>₹ 31.0L</td>\n",
       "      <td>1-4 yrs experience (based on 64 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>₹ 11.4L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>₹ 32.5L</td>\n",
       "      <td>1-4 yrs experience (based on 87 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PayPal</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 19.9L</td>\n",
       "      <td>₹ 31.0L</td>\n",
       "      <td>1-2 yrs experience (based on 29 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Myntra</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 19.5L</td>\n",
       "      <td>₹ 27.0L</td>\n",
       "      <td>1 yr experience (based on 10 salaries)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Comapnay_names minimum_salary Average_salary  \\\n",
       "0                                 Google        ₹ 11.0L        ₹ 31.3L   \n",
       "1                  Microsoft Corporation        ₹ 13.0L        ₹ 24.0L   \n",
       "2                          Goldman Sachs        ₹ 12.0L        ₹ 23.0L   \n",
       "3                                 Tekion        ₹ 12.0L        ₹ 21.2L   \n",
       "4                                 Amazon         ₹ 8.0L        ₹ 21.0L   \n",
       "5  Servicenow Software Development India        ₹ 13.0L        ₹ 20.5L   \n",
       "6                               Flipkart         ₹ 7.5L        ₹ 20.4L   \n",
       "7                                Walmart        ₹ 11.4L        ₹ 20.0L   \n",
       "8                                 PayPal        ₹ 11.0L        ₹ 19.9L   \n",
       "9                                 Myntra        ₹ 14.0L        ₹ 19.5L   \n",
       "\n",
       "  Maximum_salary                             Experiences_req  \n",
       "0        ₹ 65.0L   1-3 yrs experience (based on 35 salaries)  \n",
       "1        ₹ 50.0L  1-4 yrs experience (based on 274 salaries)  \n",
       "2        ₹ 34.0L     2 yrs experience (based on 18 salaries)  \n",
       "3        ₹ 33.0L   2-4 yrs experience (based on 35 salaries)  \n",
       "4        ₹ 45.0L  1-4 yrs experience (based on 122 salaries)  \n",
       "5        ₹ 28.0L   2-4 yrs experience (based on 60 salaries)  \n",
       "6        ₹ 31.0L   1-4 yrs experience (based on 64 salaries)  \n",
       "7        ₹ 32.5L   1-4 yrs experience (based on 87 salaries)  \n",
       "8        ₹ 31.0L   1-2 yrs experience (based on 29 salaries)  \n",
       "9        ₹ 27.0L      1 yr experience (based on 10 salaries)  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary = pd.DataFrame({})\n",
    "\n",
    "salary['Comapnay_names']=company_names\n",
    "salary['minimum_salary']=min_sal\n",
    "salary['Average_salary']=avg_sal\n",
    "salary['Maximum_salary']=max_sal\n",
    "salary['Experiences_req']=company_exp\n",
    "salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae942012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
