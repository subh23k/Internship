{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b6591f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries at once\n",
    "\n",
    "import pandas as pd\n",
    "import selenium\n",
    "import time\n",
    "from bs4 import BeautifulSoup \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import requests\n",
    "import re\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e046ae",
   "metadata": {},
   "source": [
    "## 1. Scrape the details of most viewed videos on YouTube from Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62de050f",
   "metadata": {},
   "source": [
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details: A) Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c88ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c560c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url=('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d29f850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list for storing data after scraping\n",
    "\n",
    "Rank = []\n",
    "Name = []\n",
    "Artist = []\n",
    "UploadDate = []\n",
    "Views = []\n",
    "# Scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "#scrapping rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Name.append(\"_\")\n",
    "#scrapping Artist\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//*[@id=\"mw-content-text\"]/div[1]/table[2]/tbody/tr/td[3]'):\n",
    "        Artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Artist.append(\"_\")\n",
    "#Scrapping Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,' //table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]'):\n",
    "        UploadDate.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    UploadDate.append('-')\n",
    "# Scraping Views of videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        Views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Views.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d84fac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DataFrame from scraped data\n",
    "Wiki = pd.DataFrame({})\n",
    "Wiki['Rank']=Rank\n",
    "Wiki['Name']=Name\n",
    "Wiki['Artist']=Artist\n",
    "Wiki['Upload Date']=UploadDate\n",
    "Wiki['Views']=Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ef9be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[3]</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>11.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[6]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[12]</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"[13]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"[15]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"[20]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[21]</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"[22]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[23]</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[24]</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[25]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"[30]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[31]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"[32]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"[33]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"[34]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"[35]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"[36]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Dark Horse\"[38]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Girls Like You\"[39]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"[40]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"[42]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"[43]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Lean On\"[44]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"[45]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[46]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shake It Off\"[47]</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Mi Gente\"[48]</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>3.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[3]   \n",
       "1    2.                                   \"Despacito\"[6]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[12]   \n",
       "3    4.                               \"Shape of You\"[13]   \n",
       "4    5.                              \"See You Again\"[15]   \n",
       "5    6.                                  \"Bath Song\"[20]   \n",
       "6    7.                \"Phonics Song with Two Words\"[21]   \n",
       "7    8.                                \"Uptown Funk\"[22]   \n",
       "8    9.  \"Learning Colors – Colorful Eggs on a Farm\"[23]   \n",
       "9   10.   \"Masha and the Bear – Recipe for Disaster\"[24]   \n",
       "10  11.                              \"Gangnam Style\"[25]   \n",
       "11  12.                          \"Wheels on the Bus\"[30]   \n",
       "12  13.                             \"Dame Tu Cosita\"[31]   \n",
       "13  14.                                      \"Sugar\"[32]   \n",
       "14  15.                                       \"Roar\"[33]   \n",
       "15  16.                             \"Counting Stars\"[34]   \n",
       "16  17.                                      \"Sorry\"[35]   \n",
       "17  18.                          \"Thinking Out Loud\"[36]   \n",
       "18  19.                                     \"Axel F\"[37]   \n",
       "19  20.                                 \"Dark Horse\"[38]   \n",
       "20  21.                             \"Girls Like You\"[39]   \n",
       "21  22.                                      \"Faded\"[40]   \n",
       "22  23.                        \"Baa Baa Black Sheep\"[41]   \n",
       "23  24.                                 \"Let Her Go\"[42]   \n",
       "24  25.                                   \"Bailando\"[43]   \n",
       "25  26.                                    \"Lean On\"[44]   \n",
       "26  27.                                    \"Perfect\"[45]   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"[46]   \n",
       "28  29.                               \"Shake It Off\"[47]   \n",
       "29  30.                                   \"Mi Gente\"[48]   \n",
       "\n",
       "                                         Artist        Upload Date  Views  \n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  11.05  \n",
       "1                                    Luis Fonsi   January 12, 2017   7.93  \n",
       "2                                   LooLoo Kids    October 8, 2016   6.40  \n",
       "3                                    Ed Sheeran   January 30, 2017   5.77  \n",
       "4                                   Wiz Khalifa      April 6, 2015   5.59  \n",
       "5                    Cocomelon – Nursery Rhymes        May 2, 2018   5.54  \n",
       "6                                     ChuChu TV      March 6, 2014   4.77  \n",
       "7                                   Mark Ronson  November 19, 2014   4.65  \n",
       "8                                   Miroshka TV  February 27, 2018   4.60  \n",
       "9                                    Get Movies   January 31, 2012   4.50  \n",
       "10                                          Psy      July 15, 2012   4.50  \n",
       "11                   Cocomelon – Nursery Rhymes       May 24, 2018   4.24  \n",
       "12                                    El Chombo      April 5, 2018   4.00  \n",
       "13                                     Maroon 5   January 14, 2015   3.74  \n",
       "14                                   Katy Perry  September 5, 2013   3.63  \n",
       "15                                  OneRepublic       May 31, 2013   3.62  \n",
       "16                                Justin Bieber   October 22, 2015   3.57  \n",
       "17                                   Ed Sheeran    October 7, 2014   3.48  \n",
       "18                                   Crazy Frog      June 16, 2009   3.45  \n",
       "19                                   Katy Perry  February 20, 2014   3.32  \n",
       "20                                     Maroon 5       May 31, 2018   3.32  \n",
       "21                                  Alan Walker   December 3, 2015   3.32  \n",
       "22                   Cocomelon – Nursery Rhymes      June 25, 2018   3.31  \n",
       "23                                    Passenger      July 25, 2012   3.27  \n",
       "24                             Enrique Iglesias     April 11, 2014   3.25  \n",
       "25                                  Major Lazer     March 22, 2015   3.24  \n",
       "26                                   Ed Sheeran   November 9, 2017   3.22  \n",
       "27                                      Shakira       June 4, 2010   3.21  \n",
       "28                                 Taylor Swift    August 18, 2014   3.19  \n",
       "29                                     J Balvin      June 29, 2017   3.11  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28b2aeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6dfc97",
   "metadata": {},
   "source": [
    "## 2. Scrape the details team India’s international fixtures from bcci.tv. Url = https://www.bcci.tv/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed464712",
   "metadata": {},
   "source": [
    "You need to find following details: \n",
    "\n",
    "A) Match title (I.e. 1st ODI) \n",
    "\n",
    "B) Series \n",
    "\n",
    "C) Place \n",
    "\n",
    "D) Date \n",
    "\n",
    "E) Time \n",
    "\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b20b1c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')\n",
    "\n",
    "# Getting the webpage of mentioned url \n",
    "url=('https://www.bcci.tv/')\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d49dffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clickin on International tab\n",
    "International = driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a') # click button\n",
    "International.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a91d942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE ODI SERIES 2022</td>\n",
       "      <td>1st ODI</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>18 AUG 2022</td>\n",
       "      <td>12:45 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE ODI SERIES 2022</td>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>20 AUG 2022</td>\n",
       "      <td>12:45 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INDIA TOUR OF ZIMBABWE ODI SERIES 2022</td>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>Harare Sports Club,</td>\n",
       "      <td>22 AUG 2022</td>\n",
       "      <td>12:45 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Dubai International Cricket Stadium,</td>\n",
       "      <td>28 AUG 2022</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASIA CUP 2022</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Dubai International Cricket Stadium,</td>\n",
       "      <td>31 AUG 2022</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>1st T20I</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,</td>\n",
       "      <td>20 SEP 2022</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>Vidarbha Cricket Association Stadium,</td>\n",
       "      <td>23 SEP 2022</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>Rajiv Gandhi International Stadium,</td>\n",
       "      <td>25 SEP 2022</td>\n",
       "      <td>7:30 PM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Title       Name  \\\n",
       "0   INDIA TOUR OF ZIMBABWE ODI SERIES 2022   1st ODI    \n",
       "1   INDIA TOUR OF ZIMBABWE ODI SERIES 2022   2nd ODI    \n",
       "2   INDIA TOUR OF ZIMBABWE ODI SERIES 2022   3rd ODI    \n",
       "3                            ASIA CUP 2022  1st T20I    \n",
       "4                            ASIA CUP 2022  2nd T20I    \n",
       "5  AUSTRALIA TOUR OF INDIA T20 SERIES 2022  1st T20I    \n",
       "6  AUSTRALIA TOUR OF INDIA T20 SERIES 2022  2nd T20I    \n",
       "7  AUSTRALIA TOUR OF INDIA T20 SERIES 2022  3rd T20I    \n",
       "\n",
       "                                           Place         Date       Time  \n",
       "0                            Harare Sports Club,  18 AUG 2022  12:45 PM   \n",
       "1                            Harare Sports Club,  20 AUG 2022  12:45 PM   \n",
       "2                            Harare Sports Club,  22 AUG 2022  12:45 PM   \n",
       "3           Dubai International Cricket Stadium,  28 AUG 2022   7:30 PM   \n",
       "4           Dubai International Cricket Stadium,  31 AUG 2022   7:30 PM   \n",
       "5  Punjab Cricket Association IS Bindra Stadium,  20 SEP 2022   7:30 PM   \n",
       "6          Vidarbha Cricket Association Stadium,  23 SEP 2022   7:30 PM   \n",
       "7            Rajiv Gandhi International Stadium,  25 SEP 2022   7:30 PM   "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Empty List\n",
    "Name=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]\n",
    "#Scrapping Name\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"matchOrderText ng-binding ng-scope\"]'):\n",
    "        Name.append(i.text.replace('-',\"\"))\n",
    "except NoSuchElementException:\n",
    "    Name.append('-')\n",
    "#Scrapping Series\n",
    "try:\n",
    "    \n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]'):\n",
    "        Series.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Series.append('-')\n",
    "#scrapping Place\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//span[@class=\"ng-binding ng-scope\"]'):\n",
    "        Place.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Place.append('-')\n",
    "#Scrapping Date\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]'):\n",
    "        Date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Date.append('-')\n",
    "#Scrapping Time\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]'):\n",
    "        Time.append(i.text.replace('IST',\"\"))\n",
    "except NoSuchElementException:\n",
    "    Time.append('-')\n",
    "\n",
    "    \n",
    "# Create Dataframe\n",
    "\n",
    "Fixtures=pd.DataFrame({})\n",
    "Fixtures['Title']=Series\n",
    "Fixtures['Name']=Name\n",
    "Fixtures['Place']=Place\n",
    "Fixtures['Date']=Date\n",
    "Fixtures['Time']=Time\n",
    "Fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1345ff6b",
   "metadata": {},
   "source": [
    "## 3. Scrape the details of selenium exception from guru99.com. Url = https://www.guru99.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a669f",
   "metadata": {},
   "source": [
    "You need to find following details: \n",
    "\n",
    "A) Name \n",
    "\n",
    "B) Description \n",
    "\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89d129a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a5f91a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: unknown error: failed to change window state to 'normal', current state is 'maximized'\n  (Session info: MicrosoftEdge=104.0.1293.54)\nStacktrace:\nBacktrace:\n\tMicrosoft::Applications::Events::EventProperties::unpack [0x00007FF67ACC6252+24642]\n\tMicrosoft::Applications::Events::GUID_t::GUID_t [0x00007FF67AC199A2+334098]\n\tOrdinal0 [0x00007FF67A7B7915+620821]\n\tOrdinal0 [0x00007FF67A79CBBD+510909]\n\tOrdinal0 [0x00007FF67A79A7B6+501686]\n\tOrdinal0 [0x00007FF67A799ED4+499412]\n\tOrdinal0 [0x00007FF67A839166+1151334]\n\tOrdinal0 [0x00007FF67A80EE9A+978586]\n\tOrdinal0 [0x00007FF67A82306F+1060975]\n\tOrdinal0 [0x00007FF67A80ECB3+978099]\n\tOrdinal0 [0x00007FF67A7E5F00+810752]\n\tOrdinal0 [0x00007FF67A7E7508+816392]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67AA7D558+135480]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67AA64C57+34871]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67AA67CDC+47292]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67A8C11B6+23222]\n\tMicrosoft::Applications::Events::GUID_t::GUID_t [0x00007FF67AC20EAB+364059]\n\tMicrosoft::Applications::Events::GUID_t::GUID_t [0x00007FF67AC258E4+383060]\n\tMicrosoft::Applications::Events::GUID_t::GUID_t [0x00007FF67AC25A3D+383405]\n\tMicrosoft::Applications::Events::time_ticks_t::time_ticks_t [0x00007FF67AC3034E+39918]\n\tBaseThreadInitThunk [0x00007FF8D2757034+20]\n\tRtlUserThreadStart [0x00007FF8D2DA2651+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23976/513862919.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://www.guru99.com/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mmaximize_window\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    596\u001b[0m         \"\"\"\n\u001b[0;32m    597\u001b[0m         \u001b[0mcommand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW3C_MAXIMIZE_WINDOW\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfullscreen_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    433\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 435\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    436\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    437\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: unknown error: failed to change window state to 'normal', current state is 'maximized'\n  (Session info: MicrosoftEdge=104.0.1293.54)\nStacktrace:\nBacktrace:\n\tMicrosoft::Applications::Events::EventProperties::unpack [0x00007FF67ACC6252+24642]\n\tMicrosoft::Applications::Events::GUID_t::GUID_t [0x00007FF67AC199A2+334098]\n\tOrdinal0 [0x00007FF67A7B7915+620821]\n\tOrdinal0 [0x00007FF67A79CBBD+510909]\n\tOrdinal0 [0x00007FF67A79A7B6+501686]\n\tOrdinal0 [0x00007FF67A799ED4+499412]\n\tOrdinal0 [0x00007FF67A839166+1151334]\n\tOrdinal0 [0x00007FF67A80EE9A+978586]\n\tOrdinal0 [0x00007FF67A82306F+1060975]\n\tOrdinal0 [0x00007FF67A80ECB3+978099]\n\tOrdinal0 [0x00007FF67A7E5F00+810752]\n\tOrdinal0 [0x00007FF67A7E7508+816392]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67AA7D558+135480]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67AA64C57+34871]\n\tMicrosoft::Applications::Events::EventProperty::EventProperty [0x00007FF67AA67CDC+47292]\n\tMicrosoft::Applications::Events::EventProperty::to_string [0x00007FF67A8C11B6+23222]\n\tMicrosoft::Applications::Events::GUID_t::GUID_t [0x00007FF67AC20EAB+364059]\n\tMicrosoft::Applications::Events::GUID_t::GUID_t [0x00007FF67AC258E4+383060]\n\tMicrosoft::Applications::Events::GUID_t::GUID_t [0x00007FF67AC25A3D+383405]\n\tMicrosoft::Applications::Events::time_ticks_t::time_ticks_t [0x00007FF67AC3034E+39918]\n\tBaseThreadInitThunk [0x00007FF8D2757034+20]\n\tRtlUserThreadStart [0x00007FF8D2DA2651+33]\n"
     ]
    }
   ],
   "source": [
    "# Getting the webpage of mentioned url \n",
    "url=('https://www.guru99.com/')\n",
    "driver.get(url)\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7327f8e5",
   "metadata": {},
   "source": [
    "## 4. Scrape the details of State-wise GDP of India from statisticstime.com. Url =https://www.statisticstimes.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfc1407",
   "metadata": {},
   "source": [
    "You have to find following details: \n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP(18-19)\n",
    "\n",
    "D) GSDP(17-18)\n",
    "\n",
    "E) Share(2017)\n",
    "\n",
    "F) GDP($ billion) Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faf31532",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "083b6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()\n",
    "driver.get('https://www.statisticstimes.com')\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3977e23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'/html/body/div[1]/div/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1eda46c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Clicking on Economy button\n",
    "driver.find_element(By.XPATH,\"//div[@class='navbar']/div[2]/button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "42cdfc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on India\n",
    "driver.find_element(By.XPATH,\"//div[@class='dropdown-content']/a[3]\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29bdd8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clicking on GDP of Indian Economy\n",
    "GDP = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8fd403fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty list\n",
    "Rank = []\n",
    "State = []\n",
    "GSDP1 = []\n",
    "GSDP2 = []\n",
    "Share = []\n",
    "GDPbillion = []\n",
    "# Scraping Rank\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[1]\"):\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Rank.append(\"_\")\n",
    "# Scraping State\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[2]\"):\n",
    "        State.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    State.append(\"_\")\n",
    "# Scraping GSDP at current price (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[4]\"):\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP2.append(\"_\")\n",
    "# Scraping Share (18-19)\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[5]\"):\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Share.append(\"_\")\n",
    "# Scraping GDP $ billion\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH,\"//table[@class='display dataTable']/tbody/tr/td[6]\"):\n",
    "        GDPbillion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDPbillion.append(\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69698f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1684d2",
   "metadata": {},
   "source": [
    "## 5. Scrape the details of trending repositories on Github.com. Url = https://github.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46844671",
   "metadata": {},
   "source": [
    "You have to find the following details: \n",
    "\n",
    "A) Repository title \n",
    "\n",
    "B) Repository description \n",
    "\n",
    "C) Contributors count \n",
    "\n",
    "D) Language used ASSIGNMENT \n",
    "\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "706dbe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01caba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()\n",
    "url=('https://github.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af433928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on explore\n",
    "\n",
    "explore = driver.find_element(By.XPATH,'//li[@class = \"mr-0 mr-lg-3 position-relative flex-wrap flex-justify-between flex-items-center border-bottom border-lg-bottom-0 d-block d-lg-flex flex-lg-nowrap flex-lg-items-center\"][4]')\n",
    "try:\n",
    "    explore.click()\n",
    "    time.sleep(5)\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(explore.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ba66c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on Trending\n",
    "\n",
    "trending = driver.find_element(By.XPATH,'//*[@href=\"/trending\"]')\n",
    "try:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8af96684",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "#Creating empty list\n",
    "URLs = []\n",
    "repository_title = []\n",
    "Description = []\n",
    "Contributors = []\n",
    "Language = []\n",
    "lang = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8842cef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching urls for each repository\n",
    "repository = driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']//a\")\n",
    "for i in repository:\n",
    "    URLs.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7998c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Repository Title data\n",
    "title = driver.find_elements(By.XPATH,\"//h1[@class = 'h3 lh-condensed']\")\n",
    "for i in title:\n",
    "    repository_title.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5bff117a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping data from all repository page\n",
    "for i in URLs:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "        # Scraping Repository Description data\n",
    "    try:\n",
    "        desc = driver.find_element(By.XPATH,\"//p[@class='f4 my-3']\")\n",
    "        Description.append(desc.text)\n",
    "    except NoSuchElementException:\n",
    "        Description.append('-')\n",
    "        \n",
    "        \n",
    "    # Scraping Contributors Count data\n",
    "    try:\n",
    "        contributor = driver.find_element(By.XPATH,\"//*[contains(text(),'    Contributors ')]\")\n",
    "        Contributors.append(contributor.text.replace('Contributors',''))\n",
    "    except NoSuchElementException:\n",
    "        Contributors.append('-')\n",
    "        \n",
    "        \n",
    "    # Scraping Languages used data\n",
    "    lang=[]\n",
    "    try:\n",
    "        for i in driver.find_elements(By.XPATH,'//span[@class=\"color-fg-default text-bold mr-1\"]'):\n",
    "            lang.append(i.text)\n",
    "        Language.append(lang)\n",
    "    except NoSuchElementException:\n",
    "        lang.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2b3ce163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(repository_title),len(Description),len(Contributors),len(Language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "08ab9448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toeverything / AFFiNE</td>\n",
       "      <td>There can be more than Notion and Miro. Affine...</td>\n",
       "      <td>15</td>\n",
       "      <td>[TypeScript, JavaScript, CSS, SCSS, HTML, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jwasham / coding-interview-university</td>\n",
       "      <td>A complete computer science study plan to beco...</td>\n",
       "      <td>255</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>iptv-org / iptv</td>\n",
       "      <td>Collection of publicly available IPTV channels...</td>\n",
       "      <td>181</td>\n",
       "      <td>[JavaScript, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ventoy / Ventoy</td>\n",
       "      <td>A new bootable USB solution.</td>\n",
       "      <td>74</td>\n",
       "      <td>[C, Shell, HTML, C++, CSS, Makefile, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MarlinFirmware / Marlin</td>\n",
       "      <td>Marlin is an optimized firmware for RepRap 3D ...</td>\n",
       "      <td>1,027</td>\n",
       "      <td>[C++, C, Python, Shell, JavaScript, HTML, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dreamacro / clash</td>\n",
       "      <td>A rule-based tunnel in Go.</td>\n",
       "      <td>79</td>\n",
       "      <td>[Go, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>arthurspk / guiadevbrasil</td>\n",
       "      <td>GUIA EXTENSO DE PROGRAMAÇÃO:</td>\n",
       "      <td>50</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>donnemartin / system-design-primer</td>\n",
       "      <td>Learn how to design large-scale systems. Prep ...</td>\n",
       "      <td>115</td>\n",
       "      <td>[Python, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MatrixTM / MHDDoS</td>\n",
       "      <td>Best DDoS Attack Script Python3, (Cyber / DDos...</td>\n",
       "      <td>25</td>\n",
       "      <td>[Python, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t3-oss / create-t3-app</td>\n",
       "      <td>Quickest way to start a new web app with full ...</td>\n",
       "      <td>57</td>\n",
       "      <td>[TypeScript, JavaScript, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>punk-security / dnsReaper</td>\n",
       "      <td>dnsReaper - subdomain takeover tool for attack...</td>\n",
       "      <td>8</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>juliocesarfort / public-pentesting-reports</td>\n",
       "      <td>Curated list of public penetration test report...</td>\n",
       "      <td>33</td>\n",
       "      <td>[CSS, C, JavaScript, Makefile, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>facebookresearch / ParlAI</td>\n",
       "      <td>A framework for training and evaluating AI mod...</td>\n",
       "      <td>182</td>\n",
       "      <td>[Python, HTML, JavaScript, CSS, Shell, Cuda]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>utmapp / UTM</td>\n",
       "      <td>Virtual machines for iOS and macOS</td>\n",
       "      <td>40</td>\n",
       "      <td>[Swift, Objective-C, Python, C, Shell]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>theboy181 / switch-ptchtxt-mods</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Asabeneh / 30-Days-Of-React</td>\n",
       "      <td>30 Days of React challenge is a step by step g...</td>\n",
       "      <td>8</td>\n",
       "      <td>[JavaScript, HTML, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>github / docs</td>\n",
       "      <td>The open-source repo for docs.github.com</td>\n",
       "      <td>1,362</td>\n",
       "      <td>[JavaScript, TypeScript, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>josephmisiti / awesome-machine-learning</td>\n",
       "      <td>A curated list of awesome Machine Learning fra...</td>\n",
       "      <td>547</td>\n",
       "      <td>[Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PKUFlyingPig / cs-self-learning</td>\n",
       "      <td>计算机自学指南</td>\n",
       "      <td>43</td>\n",
       "      <td>[HTML]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jina-ai / discoart</td>\n",
       "      <td>Create Disco Diffusion artworks in one line</td>\n",
       "      <td>5</td>\n",
       "      <td>[Python, Jupyter Notebook, Shell, Dockerfile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>trickest / cve</td>\n",
       "      <td>Gather and update all available and newest CVE...</td>\n",
       "      <td>7</td>\n",
       "      <td>[HTML, Python]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>HIT-UG-Group / DeepLearning-MuLi-Notes</td>\n",
       "      <td>Notes about courses Dive into Deep Learning by...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Jupyter Notebook]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>hyprwm / Hyprland</td>\n",
       "      <td>Hyprland is a dynamic tiling Wayland composito...</td>\n",
       "      <td>40</td>\n",
       "      <td>[C++, Nix, Other]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EbookFoundation / free-programming-books</td>\n",
       "      <td>📚 Freely available programming books</td>\n",
       "      <td>1,988</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>moyix / fauxpilot</td>\n",
       "      <td>FauxPilot - an open-source GitHub Copilot server</td>\n",
       "      <td>3</td>\n",
       "      <td>[Python, Shell, Dockerfile]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Repository title  \\\n",
       "0                        toeverything / AFFiNE   \n",
       "1        jwasham / coding-interview-university   \n",
       "2                              iptv-org / iptv   \n",
       "3                              ventoy / Ventoy   \n",
       "4                      MarlinFirmware / Marlin   \n",
       "5                            Dreamacro / clash   \n",
       "6                    arthurspk / guiadevbrasil   \n",
       "7           donnemartin / system-design-primer   \n",
       "8                            MatrixTM / MHDDoS   \n",
       "9                       t3-oss / create-t3-app   \n",
       "10                   punk-security / dnsReaper   \n",
       "11  juliocesarfort / public-pentesting-reports   \n",
       "12                   facebookresearch / ParlAI   \n",
       "13                                utmapp / UTM   \n",
       "14             theboy181 / switch-ptchtxt-mods   \n",
       "15                 Asabeneh / 30-Days-Of-React   \n",
       "16                               github / docs   \n",
       "17     josephmisiti / awesome-machine-learning   \n",
       "18             PKUFlyingPig / cs-self-learning   \n",
       "19                          jina-ai / discoart   \n",
       "20                              trickest / cve   \n",
       "21      HIT-UG-Group / DeepLearning-MuLi-Notes   \n",
       "22                           hyprwm / Hyprland   \n",
       "23    EbookFoundation / free-programming-books   \n",
       "24                           moyix / fauxpilot   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0   There can be more than Notion and Miro. Affine...                 15   \n",
       "1   A complete computer science study plan to beco...                255   \n",
       "2   Collection of publicly available IPTV channels...                181   \n",
       "3                        A new bootable USB solution.                 74   \n",
       "4   Marlin is an optimized firmware for RepRap 3D ...              1,027   \n",
       "5                          A rule-based tunnel in Go.                 79   \n",
       "6                        GUIA EXTENSO DE PROGRAMAÇÃO:                 50   \n",
       "7   Learn how to design large-scale systems. Prep ...                115   \n",
       "8   Best DDoS Attack Script Python3, (Cyber / DDos...                 25   \n",
       "9   Quickest way to start a new web app with full ...                 57   \n",
       "10  dnsReaper - subdomain takeover tool for attack...                  8   \n",
       "11  Curated list of public penetration test report...                 33   \n",
       "12  A framework for training and evaluating AI mod...                182   \n",
       "13                 Virtual machines for iOS and macOS                 40   \n",
       "14                                                  -                  -   \n",
       "15  30 Days of React challenge is a step by step g...                  8   \n",
       "16           The open-source repo for docs.github.com              1,362   \n",
       "17  A curated list of awesome Machine Learning fra...                547   \n",
       "18                                            计算机自学指南                 43   \n",
       "19        Create Disco Diffusion artworks in one line                  5   \n",
       "20  Gather and update all available and newest CVE...                  7   \n",
       "21  Notes about courses Dive into Deep Learning by...                  2   \n",
       "22  Hyprland is a dynamic tiling Wayland composito...                 40   \n",
       "23               📚 Freely available programming books              1,988   \n",
       "24   FauxPilot - an open-source GitHub Copilot server                  3   \n",
       "\n",
       "                                       Language used  \n",
       "0   [TypeScript, JavaScript, CSS, SCSS, HTML, Shell]  \n",
       "1                                                 []  \n",
       "2                                [JavaScript, Shell]  \n",
       "3        [C, Shell, HTML, C++, CSS, Makefile, Other]  \n",
       "4   [C++, C, Python, Shell, JavaScript, HTML, Other]  \n",
       "5                                        [Go, Other]  \n",
       "6                                                 []  \n",
       "7                                    [Python, Shell]  \n",
       "8                               [Python, Dockerfile]  \n",
       "9                    [TypeScript, JavaScript, Other]  \n",
       "10                                          [Python]  \n",
       "11             [CSS, C, JavaScript, Makefile, Shell]  \n",
       "12      [Python, HTML, JavaScript, CSS, Shell, Cuda]  \n",
       "13            [Swift, Objective-C, Python, C, Shell]  \n",
       "14                                                []  \n",
       "15                         [JavaScript, HTML, Other]  \n",
       "16                   [JavaScript, TypeScript, Other]  \n",
       "17                                          [Python]  \n",
       "18                                            [HTML]  \n",
       "19     [Python, Jupyter Notebook, Shell, Dockerfile]  \n",
       "20                                    [HTML, Python]  \n",
       "21                                [Jupyter Notebook]  \n",
       "22                                 [C++, Nix, Other]  \n",
       "23                                                []  \n",
       "24                       [Python, Shell, Dockerfile]  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA FRAMEING\n",
    "Github=pd.DataFrame({})\n",
    "Github['Repository title'] = repository_title\n",
    "Github['Repository description'] = Description\n",
    "Github['Contributors count'] = Contributors\n",
    "Github['Language used'] = Language\n",
    "Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b18014c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66f44ed",
   "metadata": {},
   "source": [
    "## 6. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adeb074",
   "metadata": {},
   "source": [
    "You have to find the following details: \n",
    "\n",
    "A) Song name \n",
    "\n",
    "B) Artist name \n",
    "\n",
    "C) Last week rank \n",
    "\n",
    "D) Peak rank \n",
    "\n",
    "E) Weeks on board \n",
    "\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "639937f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cff112f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()\n",
    "url=('https://www.billboard.com/')\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8511f629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on charts\n",
    "charts=driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/header/div[2]/div/nav/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9b682ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty lists\n",
    "Song_Name = []\n",
    "Artist_Name = []\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "Weeks_on_board = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3caec430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scraping name\n",
    "for i in driver.find_elements(By.XPATH,'//li[@class=\"lrv-u-width-100p\"]'):\n",
    "    Song_Name.append(i.text)\n",
    "len(Song_Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cceeb052",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrappin Artist name 1 st one\n",
    "\n",
    "Artist_Name.append(driver.find_element(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb0a810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remainig Artist Name\n",
    "\n",
    "artistTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "Artist_Name.extend([i.text for i in artistTag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "421ce63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scapping Rank\n",
    "rank=[]\n",
    "rankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "rank.extend([i.text for i in rankTag[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0bb4e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remaining RAnk\n",
    "Rank=[]\n",
    "RankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "Rank.extend([i.text for i in RankTag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff94500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing ''\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1a65d919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing as per requirement\n",
    "lastweekpos=Rank[0::3]\n",
    "lastweekpos.insert(0,rank[0])\n",
    "peakPos=Rank[1::3]\n",
    "peakPos.insert(0,rank[1])\n",
    "weeksonBoard=Rank[2::3]\n",
    "weeksonBoard.insert(0,rank[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b2e1e5e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 133, 133, 133)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check length of all\n",
    "len(Song_Name),len(Artist_Name),len(lastweekpos),len(peakPos),len(weeksonBoard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d2a3e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframe\n",
    "df=pd.DataFrame()\n",
    "df['SongName']=Song_Name[0:100]\n",
    "df['ArtistName']=Artist_Name\n",
    "df['Last Week']=lastweekpos[0:100]\n",
    "df[\"PeekPosition\"]=peakPos[0:100]\n",
    "df['Weeks On board']=weeksonBoard[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c583700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SongName</th>\n",
       "      <th>ArtistName</th>\n",
       "      <th>Last Week</th>\n",
       "      <th>PeekPosition</th>\n",
       "      <th>Weeks On board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Break My Soul\\nBeyonce\\n6\\n1\\n7</td>\n",
       "      <td>Beyonce</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>About Damn Time\\nLizzo\\n1\\n1\\n16</td>\n",
       "      <td>Lizzo</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As It Was\\nHarry Styles\\n2\\n1\\n18</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Running Up That Hill (A Deal With God)\\nKate B...</td>\n",
       "      <td>Kate Bush</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wait For U\\nFuture Featuring Drake &amp; Tems\\n5\\n...</td>\n",
       "      <td>Future Featuring Drake &amp; Tems</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Until I Found You\\nStephen Sanchez\\n88\\n88\\n5</td>\n",
       "      <td>Stephen Sanchez</td>\n",
       "      <td>90</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Un Ratito\\nBad Bunny\\n93\\n16\\n13</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Best Thing Since Backroads\\nJake Owen\\n72\\n72\\n4</td>\n",
       "      <td>Jake Owen</td>\n",
       "      <td>-</td>\n",
       "      <td>83</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>La Corriente\\nBad Bunny &amp; Tony Dize\\n100\\n32\\n10</td>\n",
       "      <td>Bad Bunny &amp; Tony Dize</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 52\\nBizarrap &amp; Queve...</td>\n",
       "      <td>Bizarrap &amp; Quevedo</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             SongName  \\\n",
       "0                     Break My Soul\\nBeyonce\\n6\\n1\\n7   \n",
       "1                    About Damn Time\\nLizzo\\n1\\n1\\n16   \n",
       "2                   As It Was\\nHarry Styles\\n2\\n1\\n18   \n",
       "3   Running Up That Hill (A Deal With God)\\nKate B...   \n",
       "4   Wait For U\\nFuture Featuring Drake & Tems\\n5\\n...   \n",
       "..                                                ...   \n",
       "95      Until I Found You\\nStephen Sanchez\\n88\\n88\\n5   \n",
       "96                   Un Ratito\\nBad Bunny\\n93\\n16\\n13   \n",
       "97   Best Thing Since Backroads\\nJake Owen\\n72\\n72\\n4   \n",
       "98   La Corriente\\nBad Bunny & Tony Dize\\n100\\n32\\n10   \n",
       "99  Bzrp Music Sessions, Vol. 52\\nBizarrap & Queve...   \n",
       "\n",
       "                       ArtistName Last Week PeekPosition Weeks On board  \n",
       "0                         Beyonce         6            1              7  \n",
       "1                           Lizzo         1            1             16  \n",
       "2                    Harry Styles         2            1             18  \n",
       "3                       Kate Bush         3            3             30  \n",
       "4   Future Featuring Drake & Tems         5            1             14  \n",
       "..                            ...       ...          ...            ...  \n",
       "95                Stephen Sanchez        90           82              2  \n",
       "96                      Bad Bunny                                        \n",
       "97                      Jake Owen         -           83              1  \n",
       "98          Bad Bunny & Tony Dize                                        \n",
       "99             Bizarrap & Quevedo        80           80             11  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "33dfd1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3449bc",
   "metadata": {},
   "source": [
    "## 7. Scrape the details of Data science recruiters from naukri.com. Url = https://www.naukri.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a0f56",
   "metadata": {},
   "source": [
    "You have to find the following details: A) Name B) Designation C) Company D) Skills they hire for E) Location Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "09c8c590",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce40bd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()\n",
    "url=('https://www.naukri.com/')\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6db0d9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching urls to navigate recruiter page\n",
    "recruiter = driver.find_element(By.XPATH,'//a[@title=\"Search Jobs\"]')\n",
    "page_url = recruiter.get_attribute(\"href\")\n",
    "\n",
    "driver.get(page_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d62f64a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetching urls to navigate recruiter page\n",
    "recruiter = driver.find_element(By.XPATH,'/html/body/div[1]/div/ul/li[2]/a')\n",
    "page_url = recruiter.get_attribute(\"href\")\n",
    "\n",
    "driver.get(page_url)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9071a5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching search button, sending keys and clicking on it\n",
    "search = driver.find_element(By.XPATH,\"//div[@class='inpWrap']//input\") \n",
    "search.send_keys(\"Data science \")           \n",
    "btn = driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button').click()     \n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5f75b6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Name = []\n",
    "Designation = []\n",
    "Company = []\n",
    "Skills = []\n",
    "Location = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e6651412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scraping data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='fl ellipsis']\"):\n",
    "    Name.append(i.text)\n",
    "time.sleep(3)\n",
    "#Scraping data of Designation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b3db8862",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in driver.find_elements(By.XPATH,\"//span[@class='ellipsis clr']\"):\n",
    "    Designation.append(i.text)\n",
    "#Scraping data of company name\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='vcard']//p[1]/a[2]\"):\n",
    "    Company.append(i.text)\n",
    "\n",
    "#Scraping data of locations\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='vcard']//p[1]//span\"):\n",
    "    Location.append(i.text)\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "75446d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50 50 150\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Designation),len(Company),len(Location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "71d0a900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rajiv Raj</td>\n",
       "      <td>Director</td>\n",
       "      <td>CreditVidya</td>\n",
       "      <td>Rajiv Raj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sharmistha Maity</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>ICA Edu Skills Pvt. Ltd.</td>\n",
       "      <td>Director</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Malvika Bhandari</td>\n",
       "      <td>Talent Acquisition Consultant</td>\n",
       "      <td>IMS Proschool Pvt. Ltd</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fgts Recruitment</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>FUSION GLOBAL TECHNOLOGIES AND SOLUTIONS...</td>\n",
       "      <td>Sharmistha Maity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vineet P</td>\n",
       "      <td>Opportunity Communicator</td>\n",
       "      <td>Dell Technologies</td>\n",
       "      <td>Company Recruiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Silky Sethi</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>ZS Associates {India} Pvt Ltd</td>\n",
       "      <td>Kolkata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tracy Raina</td>\n",
       "      <td>Senior HR Executive</td>\n",
       "      <td>Quatrro Global Services Pvt. Ltd.</td>\n",
       "      <td>Malvika Bhandari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HR Carzonrent</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Carzonrent (India) Pvt Ltd</td>\n",
       "      <td>Talent Acquisition Consultant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Deepti Nagle</td>\n",
       "      <td>Recruitment Executive</td>\n",
       "      <td>Nityo Infotech Services Pvt. Ltd.</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Raily Ghosh</td>\n",
       "      <td>Associate Manager Human Resources</td>\n",
       "      <td>ncyclo Corporation</td>\n",
       "      <td>Fgts Recruitment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Company Recruiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Chennai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Prhemnath N R</td>\n",
       "      <td>Assistant Manager</td>\n",
       "      <td>Enfosys Pvt Ltd</td>\n",
       "      <td>Vineet P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vaishnavi Kudalkar</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Codeachive learning</td>\n",
       "      <td>Opportunity Communicator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Urvi Kumar</td>\n",
       "      <td>Talent Recruiter</td>\n",
       "      <td>Augment Systems Pvt Ltd</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Silky Sethi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Rohan Aditya Gupta</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Atria Institute of Technology</td>\n",
       "      <td>Company Recruiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Infinitive Software Solutions</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Tracy Raina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bhavani Tannedi</td>\n",
       "      <td>Senior Technical Recruiter</td>\n",
       "      <td>Intelliswift Software</td>\n",
       "      <td>Senior HR Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Archana</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>SRIT India pvt ltd</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>HR Carzonrent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Rajesh Kumar Sahu</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Excellent Academy</td>\n",
       "      <td>Company Recruiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Kranti Singh</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Megamax Global Solutions Pvt. Ltd.</td>\n",
       "      <td>Deepti Nagle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sreekanth Putsala</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Aquilus International Pvt Ltd</td>\n",
       "      <td>Recruitment Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Chayya Jain</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>GeeksforGeeks</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Welson James</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>premierhealthcare</td>\n",
       "      <td>Raily Ghosh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>Associate Manager Human Resources</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>BIZ INFOTECNO PRIVATE LIMITED</td>\n",
       "      <td>Aakash Harit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>HR Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>Company HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Pune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Helpageyouth Foundation</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>HelpageYouth Foundation</td>\n",
       "      <td>Prhemnath N R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>Assistant Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>che</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Divyangana Singh</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>DIGIGRAINS</td>\n",
       "      <td>Vaishnavi Kudalkar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Anusha B</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>IndOz TechSol</td>\n",
       "      <td>HR Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Akshatha TY</td>\n",
       "      <td>HR executive</td>\n",
       "      <td>square n cube</td>\n",
       "      <td>Urvi Kumar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Deepak Yadav</td>\n",
       "      <td>Manager HR Administration</td>\n",
       "      <td>Synopsis Recruiters</td>\n",
       "      <td>Talent Recruiter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Manu Jain</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Tech Mahindra Limited</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Jagjyot Singh</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>subhas patel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rashmi S</td>\n",
       "      <td>HR Executive Talent Acquisition</td>\n",
       "      <td>Prolim Corporation</td>\n",
       "      <td>Founder CEO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Poly Das</td>\n",
       "      <td>IT Recruiter</td>\n",
       "      <td>Intertec Softwares</td>\n",
       "      <td>UK - (london)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Hemavathy Balachandran</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Admatic Solutions</td>\n",
       "      <td>Rohan Aditya Gupta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Uday Kumar Goparaju</td>\n",
       "      <td>HR Coordinator</td>\n",
       "      <td>CoreCompete Pvt Ltd</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                       Rajiv Raj   \n",
       "1                                Sharmistha Maity   \n",
       "2                                Malvika Bhandari   \n",
       "3                                Fgts Recruitment   \n",
       "4                                        Vineet P   \n",
       "5                                     Silky Sethi   \n",
       "6                                     Tracy Raina   \n",
       "7                                   HR Carzonrent   \n",
       "8                                    Deepti Nagle   \n",
       "9                                     Raily Ghosh   \n",
       "10                                   Aakash Harit   \n",
       "11                       MARSIAN Technologies LLP   \n",
       "12                                  Prhemnath N R   \n",
       "13                             Vaishnavi Kudalkar   \n",
       "14                                     Urvi Kumar   \n",
       "15                                   subhas patel   \n",
       "16                             Rohan Aditya Gupta   \n",
       "17                                 Priyanka Akiri   \n",
       "18                                Kalpana Dumpala   \n",
       "19                                Bhavani Tannedi   \n",
       "20                                        Archana   \n",
       "21                                        Mubarak   \n",
       "22                              Rajesh Kumar Sahu   \n",
       "23                                 Kushal Rastogi   \n",
       "24                                   Kranti Singh   \n",
       "25                              Sreekanth Putsala   \n",
       "26                                    Chayya Jain   \n",
       "27                                   Welson James   \n",
       "28                             Mahesh Babu Channa   \n",
       "29                                   Kapil Devang   \n",
       "30                                Sakshi Chhikara   \n",
       "31   Abhishek - Only Analytics Hiring - India and   \n",
       "32  Institute for Financial Management and Resear   \n",
       "33                                    Ruchi Dhote   \n",
       "34                                  Manisha Yadav   \n",
       "35                                    Riya Rajesh   \n",
       "36                        Helpageyouth Foundation   \n",
       "37                           Rashmi Bhattacharjee   \n",
       "38                                  Faizan Kareem   \n",
       "39                               Divyangana Singh   \n",
       "40                                       Anusha B   \n",
       "41                                 Rithika dadwal   \n",
       "42                                    Akshatha TY   \n",
       "43                                   Deepak Yadav   \n",
       "44                                      Manu Jain   \n",
       "45                                  Jagjyot Singh   \n",
       "46                                       Rashmi S   \n",
       "47                                       Poly Das   \n",
       "48                         Hemavathy Balachandran   \n",
       "49                            Uday Kumar Goparaju   \n",
       "\n",
       "                            Designation  \\\n",
       "0                              Director   \n",
       "1                     Company Recruiter   \n",
       "2         Talent Acquisition Consultant   \n",
       "3                     Company Recruiter   \n",
       "4              Opportunity Communicator   \n",
       "5                     Company Recruiter   \n",
       "6                   Senior HR Executive   \n",
       "7                     Company Recruiter   \n",
       "8                 Recruitment Executive   \n",
       "9     Associate Manager Human Resources   \n",
       "10                           HR Manager   \n",
       "11                           Company HR   \n",
       "12                    Assistant Manager   \n",
       "13                         HR Executive   \n",
       "14                     Talent Recruiter   \n",
       "15                          Founder CEO   \n",
       "16              Manager Human Resources   \n",
       "17                           HR Manager   \n",
       "18                     Executive Hiring   \n",
       "19           Senior Technical Recruiter   \n",
       "20                       Human Resource   \n",
       "21                           Company HR   \n",
       "22                           Company HR   \n",
       "23                           Company HR   \n",
       "24                           Company HR   \n",
       "25                           Company HR   \n",
       "26                           Company HR   \n",
       "27                           Company HR   \n",
       "28                         HR Team Lead   \n",
       "29                           HR Manager   \n",
       "30                 Assistant Manager HR   \n",
       "31          Recruitment Lead Consultant   \n",
       "32                    Programme Manager   \n",
       "33  Senior Executive Talent Acquisition   \n",
       "34                         HR Executive   \n",
       "35           Manager Talent Acquisition   \n",
       "36                         HR Executive   \n",
       "37                              HR Head   \n",
       "38                           HR MANAGER   \n",
       "39                         HR Executive   \n",
       "40                           HR Manager   \n",
       "41                         HR Recruiter   \n",
       "42                         HR executive   \n",
       "43            Manager HR Administration   \n",
       "44                           HR Manager   \n",
       "45                           HR Manager   \n",
       "46      HR Executive Talent Acquisition   \n",
       "47                         IT Recruiter   \n",
       "48                         HR Recruiter   \n",
       "49                       HR Coordinator   \n",
       "\n",
       "                                        Company  \\\n",
       "0                                   CreditVidya   \n",
       "1                      ICA Edu Skills Pvt. Ltd.   \n",
       "2                        IMS Proschool Pvt. Ltd   \n",
       "3   FUSION GLOBAL TECHNOLOGIES AND SOLUTIONS...   \n",
       "4                             Dell Technologies   \n",
       "5                 ZS Associates {India} Pvt Ltd   \n",
       "6             Quatrro Global Services Pvt. Ltd.   \n",
       "7                    Carzonrent (India) Pvt Ltd   \n",
       "8             Nityo Infotech Services Pvt. Ltd.   \n",
       "9                            ncyclo Corporation   \n",
       "10                         Data Science Network   \n",
       "11                     MARSIAN Technologies LLP   \n",
       "12                              Enfosys Pvt Ltd   \n",
       "13                          Codeachive learning   \n",
       "14                      Augment Systems Pvt Ltd   \n",
       "15                              LibraryXProject   \n",
       "16                Atria Institute of Technology   \n",
       "17                Infinitive Software Solutions   \n",
       "18                           Innominds Software   \n",
       "19                        Intelliswift Software   \n",
       "20                           SRIT India pvt ltd   \n",
       "21                                     MoneyTap   \n",
       "22                            Excellent Academy   \n",
       "23           QuantMagnum Technologies Pvt. Ltd.   \n",
       "24           Megamax Global Solutions Pvt. Ltd.   \n",
       "25                Aquilus International Pvt Ltd   \n",
       "26                                GeeksforGeeks   \n",
       "27                            premierhealthcare   \n",
       "28                            SocialPrachar.com   \n",
       "29                               BISP Solutions   \n",
       "30                BIZ INFOTECNO PRIVATE LIMITED   \n",
       "31   Apidel Technologies Division of Transpower   \n",
       "32                                         IFMR   \n",
       "33                        Bristlecone India Ltd   \n",
       "34                                     Easi Tax   \n",
       "35                  Novelworx Digital Solutions   \n",
       "36                      HelpageYouth Foundation   \n",
       "37      AXESTRACK SOFTWARE SOLUTIONS PRIVATE...   \n",
       "38                FirstTech Consaltants Pvt.Ltd   \n",
       "39                                   DIGIGRAINS   \n",
       "40                                IndOz TechSol   \n",
       "41                             Affine Analytics   \n",
       "42                                square n cube   \n",
       "43                          Synopsis Recruiters   \n",
       "44                        Tech Mahindra Limited   \n",
       "45                                       Amazon   \n",
       "46                           Prolim Corporation   \n",
       "47                           Intertec Softwares   \n",
       "48                            Admatic Solutions   \n",
       "49                          CoreCompete Pvt Ltd   \n",
       "\n",
       "                             Location  \n",
       "0                           Rajiv Raj  \n",
       "1                            Director  \n",
       "2                              Mumbai  \n",
       "3                    Sharmistha Maity  \n",
       "4                   Company Recruiter  \n",
       "5                             Kolkata  \n",
       "6                    Malvika Bhandari  \n",
       "7       Talent Acquisition Consultant  \n",
       "8                                Pune  \n",
       "9                    Fgts Recruitment  \n",
       "10                  Company Recruiter  \n",
       "11                            Chennai  \n",
       "12                           Vineet P  \n",
       "13           Opportunity Communicator  \n",
       "14              Bengaluru / Bangalore  \n",
       "15                        Silky Sethi  \n",
       "16                  Company Recruiter  \n",
       "17                               Pune  \n",
       "18                        Tracy Raina  \n",
       "19                Senior HR Executive  \n",
       "20                            Gurgaon  \n",
       "21                      HR Carzonrent  \n",
       "22                  Company Recruiter  \n",
       "23                              Delhi  \n",
       "24                       Deepti Nagle  \n",
       "25              Recruitment Executive  \n",
       "26                               Pune  \n",
       "27                        Raily Ghosh  \n",
       "28  Associate Manager Human Resources  \n",
       "29           Hyderabad / Secunderabad  \n",
       "30                       Aakash Harit  \n",
       "31                         HR Manager  \n",
       "32                              Delhi  \n",
       "33           MARSIAN Technologies LLP  \n",
       "34                         Company HR  \n",
       "35                               Pune  \n",
       "36                      Prhemnath N R  \n",
       "37                  Assistant Manager  \n",
       "38                                che  \n",
       "39                 Vaishnavi Kudalkar  \n",
       "40                       HR Executive  \n",
       "41                             Mumbai  \n",
       "42                         Urvi Kumar  \n",
       "43                   Talent Recruiter  \n",
       "44                              Delhi  \n",
       "45                       subhas patel  \n",
       "46                        Founder CEO  \n",
       "47                      UK - (london)  \n",
       "48                 Rohan Aditya Gupta  \n",
       "49            Manager Human Resources  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for scraped data\n",
    "Naukri=pd.DataFrame({})\n",
    "Naukri['Name'] = Name\n",
    "Naukri['Designation'] = Designation\n",
    "Naukri['Company'] = Company\n",
    "Naukri['Location'] = Location[:50]\n",
    "Naukri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ed229d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b2395d",
   "metadata": {},
   "source": [
    "## Q8: Scrape the details of Highest selling novels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4810d26d",
   "metadata": {},
   "source": [
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0380221e",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "95211d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()\n",
    "url=('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare/')\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2b14774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list\n",
    "Bookname = []\n",
    "Authorname = []\n",
    "Volumessold = []\n",
    "Publisher = []\n",
    "Genre = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c1ca0df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping book names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody//tr/td[2]\"):\n",
    "    Bookname.append(i.text)\n",
    "#Scraping author names data\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[3]\"):\n",
    "    try:\n",
    "        if i.text == '0' : raise NoSuchElementException\n",
    "        Authorname.append(i.text)\n",
    "    except NoSuchElementException:\n",
    "        Authorname.append('-')\n",
    "time.sleep(1)\n",
    "#Scraping data of volumes sold\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[4]\"):\n",
    "    Volumessold.append(i.text)\n",
    "#Scraping data of publisher names\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[5]\"):\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//tbody/tr/td[6]\"):\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "92167fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volume sold        Publisher                        Genre  \n",
       "0    5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1    4,475,152       Bloomsbury           Children's Fiction  \n",
       "2    4,200,654       Bloomsbury           Children's Fiction  \n",
       "3    4,179,479       Bloomsbury           Children's Fiction  \n",
       "4    3,758,936     Random House              Romance & Sagas  \n",
       "..         ...              ...                          ...  \n",
       "95     807,311     Random House   General & Literary Fiction  \n",
       "96     794,201          Penguin        Food & Drink: General  \n",
       "97     792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98     791,507            Orion           Biography: General  \n",
       "99     791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating dataframe for scraped data\n",
    "Novels=pd.DataFrame({})\n",
    "Novels['Book Name'] = Bookname\n",
    "Novels['Author'] = Authorname\n",
    "Novels['Volume sold'] = Volumessold\n",
    "Novels['Publisher'] = Publisher\n",
    "Novels['Genre'] = Genre\n",
    "Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4afead61",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b016616a",
   "metadata": {},
   "source": [
    "## Q9: Scrape the details most watched tv series of all time from imdb.com."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d234e15",
   "metadata": {},
   "source": [
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3d3f6a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8655063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()\n",
    "url=('https://www.imdb.com/list/ls095964455/')\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1677fd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists.\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings = []\n",
    "Votes = []\n",
    "#Scraping data of Names\n",
    "for i in driver.find_elements(By.XPATH,\"//h3[@class='lister-item-header']/a\"):\n",
    "    Name.append(i.text)\n",
    "#Scraping data of Year span\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\"):\n",
    "    Year_span.append(i.text)\n",
    "#Scraping data of Run time\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='runtime']\"):\n",
    "    Run_time.append(i.text)\n",
    "#Scraping data of Ratings\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='ipl-rating-star small']//span[2]\"):\n",
    "    Ratings.append(i.text)\n",
    "#Scraping data of genre\n",
    "for i in driver.find_elements(By.XPATH,\"//span[@class='genre']\"):\n",
    "    Genre.append(i.text)\n",
    "#Scraping data of votes\n",
    "for i in driver.find_elements(By.XPATH,\"//div[@class='lister-item-content']//p[4]/span[2]\"):\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "66c6399c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,020,928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016– )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,117,040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>959,592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>286,878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>246,476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>60,147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005–2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>193,389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>40,802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>233,284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016– )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005–2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,020,928  \n",
       "1    51 min     8.7  1,117,040  \n",
       "2    44 min     8.2    959,592  \n",
       "3    60 min     7.5    286,878  \n",
       "4    43 min     7.6    246,476  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     49,263  \n",
       "96   50 min     7.8     60,147  \n",
       "97   42 min     8.1    193,389  \n",
       "98   45 min     7.1     40,802  \n",
       "99  572 min     8.6    233,284  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for scraped data\n",
    "TVseries=pd.DataFrame({})\n",
    "TVseries['Name'] = Name\n",
    "TVseries['Year Span'] = Year_span\n",
    "TVseries['Genre'] = Genre\n",
    "TVseries['Run Time'] = Run_time\n",
    "TVseries['Ratings'] = Ratings\n",
    "TVseries['Votes'] = Votes\n",
    "TVseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "685e8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5aa36b",
   "metadata": {},
   "source": [
    "## Q10: Details of Datasets from UCI machine learning repositories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a478e795",
   "metadata": {},
   "source": [
    "Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year\n",
    "\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be923e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Edge(r'C:\\Users\\srpandey\\Downloads\\edgedriver_win64\\msedgedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ecae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()\n",
    "url=('https://archive.ics.uci.edu/')\n",
    "driver.get(url)\n",
    "time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14793107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding view all dataset button from the webpage\n",
    "viewall_dataset = driver.find_element(By.XPATH,\"//tbody[1]//tr/td[2]/span[2]/a\")    \n",
    "page_url = viewall_dataset.get_attribute(\"href\")\n",
    "driver.get(page_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "477ce9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching page urls of all datasets \n",
    "view_list = driver.find_element(By.XPATH,\"/html/body/table[2]/tbody/tr/td[2]/table[1]/tbody/tr/td[2]/p/a\")  \n",
    "list_url = view_list.get_attribute(\"href\")           \n",
    "driver.get(list_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e02d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching urls for each dataset\n",
    "dataset_url = driver.find_elements(By.XPATH,\"//p[@class='normal']//b/a\")    \n",
    "\n",
    "urls = []     \n",
    "for i in dataset_url:\n",
    "    urls.append(i.get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1451555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty lists\n",
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attributes = []\n",
    "Year = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7444f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #Scraping Dataset name\n",
    "    try: \n",
    "        dataset_name = driver.find_element(By.XPATH,\"//span[@class='heading']\")\n",
    "        Dataset_name.append(dataset_name.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append('-')\n",
    "    \n",
    "    \n",
    "    #Scraping data type\n",
    "    try:\n",
    "        data_type = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr/td[2]\")\n",
    "        if data_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Data_type.append(data_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append('-')\n",
    "    \n",
    "    \n",
    "    #scraping Task\n",
    "    try:\n",
    "        task = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[3]/td[2]\")\n",
    "        if task.text == \"N/A\": raise NoSuchElementException\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping Attribute type\n",
    "    try:\n",
    "        attribute_type = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[2]\")\n",
    "        if attribute_type.text == \"N/A\": raise NoSuchElementException\n",
    "        Attribute_type.append(attribute_type.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping No of instances\n",
    "    try:\n",
    "        instances = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr/td[4]\")\n",
    "        if instances.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_instances.append(instances.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping No of attributes\n",
    "    try:\n",
    "        attribute = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[4]\")\n",
    "        if attribute.text == \"N/A\": raise NoSuchElementException\n",
    "        No_of_attributes.append(attribute.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_attributes.append('-')\n",
    "    \n",
    "    \n",
    "    # Scraping year\n",
    "    try:\n",
    "        year = driver.find_element(By.XPATH,\"//table[@border='1']//tbody/tr[2]/td[6]\")\n",
    "        if year.text == \"N/A\": raise NoSuchElementException\n",
    "        Year.append(year.text[:4])\n",
    "    except NoSuchElementException:\n",
    "        Year.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e918e9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instance</th>\n",
       "      <th>No of attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.4 GHZ Indoor Channel Measurements Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>7840</td>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3D Road Network (North Jutland, Denmark) Data Set</td>\n",
       "      <td>Sequential, Text</td>\n",
       "      <td>Regression, Clustering</td>\n",
       "      <td>Real</td>\n",
       "      <td>434874</td>\n",
       "      <td>4</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3W dataset Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>1984</td>\n",
       "      <td>8</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9mers from cullpdb Data Set</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>158716</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>: Simulated Data set of Iraqi tourism places D...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>-</td>\n",
       "      <td>232</td>\n",
       "      <td>16</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Youtube cookery channels viewers comments in H...</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>9800</td>\n",
       "      <td>3</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>YouTube Multiview Video Games Dataset Data Set</td>\n",
       "      <td>Multivariate, Text</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>120000</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>YouTube Spam Collection Data Set</td>\n",
       "      <td>Text</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>1956</td>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Z-Alizadeh Sani Data Set</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>56</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Zoo Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>101</td>\n",
       "      <td>17</td>\n",
       "      <td>1990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Data Name  \\\n",
       "0         2.4 GHZ Indoor Channel Measurements Data Set   \n",
       "1    3D Road Network (North Jutland, Denmark) Data Set   \n",
       "2                                  3W dataset Data Set   \n",
       "3                          9mers from cullpdb Data Set   \n",
       "4    : Simulated Data set of Iraqi tourism places D...   \n",
       "..                                                 ...   \n",
       "617  Youtube cookery channels viewers comments in H...   \n",
       "618     YouTube Multiview Video Games Dataset Data Set   \n",
       "619                   YouTube Spam Collection Data Set   \n",
       "620                           Z-Alizadeh Sani Data Set   \n",
       "621                                       Zoo Data Set   \n",
       "\n",
       "                     Data Type                        Task  \\\n",
       "0                 Multivariate              Classification   \n",
       "1             Sequential, Text      Regression, Clustering   \n",
       "2    Multivariate, Time-Series  Classification, Clustering   \n",
       "3                   Sequential  Classification, Regression   \n",
       "4                 Multivariate  Classification, Clustering   \n",
       "..                         ...                         ...   \n",
       "617         Multivariate, Text              Classification   \n",
       "618         Multivariate, Text  Classification, Clustering   \n",
       "619                       Text              Classification   \n",
       "620                          -              Classification   \n",
       "621               Multivariate              Classification   \n",
       "\n",
       "           Attribute type No of instance No of attributes  Year  \n",
       "0                    Real           7840                5  2018  \n",
       "1                    Real         434874                4  2013  \n",
       "2           Integer, Real           1984                8  2019  \n",
       "3                    Real         158716                4  2021  \n",
       "4                       -            232               16  2020  \n",
       "..                    ...            ...              ...   ...  \n",
       "617                     -           9800                3  2019  \n",
       "618         Integer, Real         120000          1000000  2013  \n",
       "619                     -           1956                5  2017  \n",
       "620         Integer, Real            303               56  2017  \n",
       "621  Categorical, Integer            101               17  1990  \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dataframe for scraped data\n",
    "ML=pd.DataFrame({})\n",
    "ML['Data Name'] = Dataset_name[:643]\n",
    "ML['Data Type'] = Data_type[:643]\n",
    "ML['Task'] = Task[:643]\n",
    "ML['Attribute type'] = Attribute_type[:643]\n",
    "ML['No of instance'] = No_of_instances\n",
    "ML['No of attributes'] = No_of_attributes[:643]\n",
    "ML['Year'] = Year[:643]\n",
    "ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d782636",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
